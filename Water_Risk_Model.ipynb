{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt6QLi_Eidbq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/BKB_WaterQualityData_2020084.csv\")"
      ],
      "metadata": {
        "id": "0Yd4ZSixikVu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9ywNwoerizsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop(columns=[\"Secchi Depth (m)\", \"Air Temp-Celsius\", \"Air Temp (?F)\", \"AirTemp (C)\", \"Unit_Id\"])"
      ],
      "metadata": {
        "id": "nYl7_6Exjvnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "SG2YpSM8kwWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe()"
      ],
      "metadata": {
        "id": "pKtI-OD4l6-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "5asMZrSFmbdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_pollution(row):\n",
        "    # Classify Dissolved Oxygen (DO) based on WHO standards\n",
        "    if row['Dissolved Oxygen (mg/L)'] < 4.0:\n",
        "        row['DO_Category'] = 'High Pollution'\n",
        "    elif row['Dissolved Oxygen (mg/L)'] <= 6.0:\n",
        "        row['DO_Category'] = 'Moderate Pollution'\n",
        "    else:\n",
        "        row['DO_Category'] = 'Low Pollution'\n",
        "\n",
        "    if row['pH (standard units)'] < 6.0:\n",
        "        row['pH_Category'] = 'High Pollution'\n",
        "    elif row['pH (standard units)'] <= 8.5:\n",
        "        row['pH_Category'] = 'Low Pollution'\n",
        "    else:\n",
        "        row['pH_Category'] = 'High Pollution'\n",
        "\n",
        "    if row['Water Temp (?C)'] > 30:\n",
        "        row['Temp_Category'] = 'High Pollution'\n",
        "    elif row['Water Temp (?C)'] >= 10:\n",
        "        row['Temp_Category'] = 'Low Pollution'\n",
        "    else:\n",
        "        row['Temp_Category'] = 'Low Pollution'\n",
        "\n",
        "    # Classify Salinity based on WHO standards\n",
        "    if row['Salinity (ppt)'] > 10:\n",
        "        row['Salinity_Category'] = 'High Pollution'\n",
        "    elif row['Salinity (ppt)'] > 1:\n",
        "        row['Salinity_Category'] = 'Moderate Pollution'\n",
        "    else:\n",
        "        row['Salinity_Category'] = 'Low Pollution'\n",
        "\n",
        "    return row"
      ],
      "metadata": {
        "id": "T6iOG_m_mf9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the classify_pollution function to each row in the dataframe\n",
        "df1 = df1.apply(classify_pollution, axis=1)\n",
        "\n",
        "# Check the new columns to verify the categorization\n",
        "df1[['Dissolved Oxygen (mg/L)', 'DO_Category', 'pH (standard units)', 'pH_Category', 'Water Temp (?C)', 'Temp_Category', 'Salinity (ppt)', 'Salinity_Category']].head()"
      ],
      "metadata": {
        "id": "7k9ok1JVowZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the assign_overall_pollution function\n",
        "def assign_overall_pollution(row):\n",
        "    # Count the number of 'High Pollution' categories\n",
        "    high_pollution_count = sum([row['DO_Category'] == 'High Pollution',\n",
        "                                 row['pH_Category'] == 'High Pollution',\n",
        "                                 row['Temp_Category'] == 'High Pollution',\n",
        "                                 row['Salinity_Category'] == 'High Pollution'])\n",
        "\n",
        "    # Assign overall pollution category based on count\n",
        "    if high_pollution_count >= 3:\n",
        "        row['Overall_Pollution'] = 'High'\n",
        "    elif high_pollution_count >= 1:\n",
        "        row['Overall_Pollution'] = 'Moderate'\n",
        "    else:\n",
        "        row['Overall_Pollution'] = 'Low'\n",
        "\n",
        "    return row\n",
        "\n",
        "# Apply the classify_pollution function to each row in the dataframe\n",
        "df1 = df1.apply(classify_pollution, axis=1)\n",
        "\n",
        "# Apply the function to assign an overall pollution category\n",
        "df1 = df1.apply(assign_overall_pollution, axis=1) # Changed df to df1\n",
        "\n",
        "# Check the final result with overall pollution column\n",
        "df1[['DO_Category', 'pH_Category', 'Temp_Category', 'Salinity_Category', 'Overall_Pollution']].head()\n"
      ],
      "metadata": {
        "id": "uV6tp679pUuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "8CD1Oel1pbho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "Y279vj78qB0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop(columns=[\"Secchi Depth (m)\", \"Air Temp-Celsius\", \"Air Temp (?F)\", \"AirTemp (C)\", \"Unit_Id\"])"
      ],
      "metadata": {
        "id": "7ffkRkjoqPAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "1ZKJsknVqRKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop(columns=[\"Field_Tech\", \"DateVerified\", \"WhoVerified\", \"Field_Tech\", \"Secchi Depth (m)\", \"Air Temp-Celsius\", \"Air Temp (?F)\", \"AirTemp (C)\", \"Unit_Id\"])"
      ],
      "metadata": {
        "id": "e6b1oLbLqYWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "uCDKnnM2qoJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "7Zpyi9FWrPOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the Salinity column, excluding NaN values\n",
        "mean_salinity = df1['Salinity (ppt)'].mean()\n",
        "\n",
        "# Print the mean value\n",
        "print(f\"Mean Salinity: {mean_salinity}\")"
      ],
      "metadata": {
        "id": "Lw-NXeMnrnD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill the missing values in the Salinity column with the mean value\n",
        "df1['Salinity (ppt)'] = df1['Salinity (ppt)'].fillna(df1['Salinity (ppt)'].mean())\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Salinity (ppt)'].isnull().sum()\n"
      ],
      "metadata": {
        "id": "BrFq_TUPs5pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[[\"Salinity (ppt)\"]].head()"
      ],
      "metadata": {
        "id": "NKBQXqnutLN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'Dissolved Oxygen (Mg/L)' with 'Dissolved Oxygen (mg/L)'\n",
        "df1['Dissolved Oxygen (mg/L)'] = df1['Dissolved Oxygen (mg/L)'].fillna(df1['Dissolved Oxygen (mg/L)'].mean())\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Dissolved Oxygen (mg/L)'].isnull().sum()"
      ],
      "metadata": {
        "id": "on9kJWl5uymu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['pH (standard units)'] = df1['pH (standard units)'].fillna(df1['pH (standard units)'].mean())\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['pH (standard units)'].isnull().sum()"
      ],
      "metadata": {
        "id": "TiwOwQ6OvpOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Water Depth (m)'] = df1['Water Depth (m)'].fillna(df1['Water Depth (m)'].mean())\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Water Depth (m)'].isnull().sum()"
      ],
      "metadata": {
        "id": "EA-_7kywwmfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Water Temp (?C)'] = df1['Water Temp (?C)'].fillna(df1['Water Temp (?C)'].mean())\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Water Temp (?C)'].isnull().sum()"
      ],
      "metadata": {
        "id": "othy8ElHxVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Time (24:00)' column to datetime objects\n",
        "df1['Time (24:00)'] = pd.to_datetime(df1['Time (24:00)'], errors='coerce').dt.time\n",
        "\n",
        "# Fill NaN values with the mode (most frequent time)\n",
        "# Calculating the mean for time data is not meaningful.\n",
        "mode_time = df1['Time (24:00)'].mode()[0]\n",
        "df1['Time (24:00)'] = df1['Time (24:00)'].fillna(mode_time)\n",
        "\n",
        "# Check if missing values are filled\n",
        "print(df1['Time (24:00)'].isnull().sum())"
      ],
      "metadata": {
        "id": "_HmJQVqxzuYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Read_Date' column to datetime objects, handling errors\n",
        "df1['Read_Date'] = pd.to_datetime(df1['Read_Date'], errors='coerce')\n",
        "\n",
        "# Now you can fill NaN values with the mean (if appropriate for your data)\n",
        "# If you want to fill with a specific date, use pd.Timestamp('your_date') instead of mean\n",
        "# For example, to fill with today's date:\n",
        "# df1['Read_Date'] = df1['Read_Date'].fillna(pd.Timestamp.today())\n",
        "\n",
        "# Alternatively, to fill with the most frequent date:\n",
        "mode_date = df1['Read_Date'].mode()[0]  # Get the most frequent date\n",
        "df1['Read_Date'] = df1['Read_Date'].fillna(mode_date)\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Read_Date'].isnull().sum()"
      ],
      "metadata": {
        "id": "EsknTWMG0y1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Site_Id' column to numeric, handling errors by coercing non-numeric values to NaN\n",
        "df1['Site_Id'] = pd.to_numeric(df1['Site_Id'], errors='coerce')\n",
        "\n",
        "# Now you can fill NaN values with the mode\n",
        "# Check if mode is empty before accessing it\n",
        "modes = df1['Site_Id'].mode()\n",
        "if not modes.empty:\n",
        "    mode_site_id = modes[0]\n",
        "    df1['Site_Id'] = df1['Site_Id'].fillna(mode_site_id)\n",
        "else:\n",
        "    # Handle the case when mode is empty, e.g., fill with a default value\n",
        "    df1['Site_Id'] = df1['Site_Id'].fillna(-1)  # Replace -1 with your desired default value\n",
        "\n",
        "# Check if missing values are filled\n",
        "df1['Site_Id'].isnull().sum()"
      ],
      "metadata": {
        "id": "82RB4M791OEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "VmrMlxpMqV_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define thresholds based on WHO/EPA standards\n",
        "df1['Contamination_Risk'] = (\n",
        "    (df1['pH (standard units)'] < 6.5) | (df1['pH (standard units)'] > 8.5) |\n",
        "    (df1['Dissolved Oxygen (mg/L)'] < 5.0) |\n",
        "    (df1['Salinity (ppt)'] > 35) |\n",
        "    (df1['Water Temp (?C)'] > 30)\n",
        ").astype(int)  # 1 = High risk, 0 = Low risk\n",
        "\n",
        "# Optional: Check class balance\n",
        "print(df1['Contamination_Risk'].value_counts())\n",
        "\n",
        "# Save the labeled dataset\n",
        "df1.to_csv('labeled_water_data.csv', index=False)\n",
        "print(\"✅ 'Contamination_Risk' column created and saved successfully.\")\n"
      ],
      "metadata": {
        "id": "aO_NUsdOseLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "EnkF8uw7spdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.drop(columns=[\"Site_Id\", \"Read_Date\", \"Time (24:00)\", \"Year\"], axis=1)"
      ],
      "metadata": {
        "id": "lwE-VAiBtQH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "KBvFlfh1tjy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "pAAc1tcytrjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.drop('Contamination_Risk', axis=1)\n",
        "y = df2['Contamination_Risk']"
      ],
      "metadata": {
        "id": "lVJ-yp-Ot1iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "Po6aEshFuHBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "bzGcjU63uKLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "8kpHccs4uNRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "iRbO9nTGuVsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔍 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n📊 Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "pxgsJdAYvCVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Get the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"✅ Model Accuracy Score: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "_xE7V_iRv1ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score # Import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np # Import numpy for np.mean and np.std\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Perform 5-Fold Cross-Validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print Cross-Validation Results\n",
        "print(f\"Cross-Validation Scores (5-fold): {cv_scores}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cv_scores):.4f}\")\n",
        "print(f\"Standard Deviation of Accuracy: {np.std(cv_scores):.4f}\")"
      ],
      "metadata": {
        "id": "VNnL6IC8wgRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save trained model\n",
        "joblib.dump(model, 'water_risk_model.pkl')\n"
      ],
      "metadata": {
        "id": "XvOCKY0uD1S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "CrmirmpULJBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "model = joblib.load(\"water_risk_model.pkl\")\n",
        "\n",
        "def predict_water_risk(salinity, do, ph, depth, temp):\n",
        "    features = np.array([[salinity, do, ph, depth, temp]])\n",
        "    prediction = model.predict(features)[0]\n",
        "    return \"⚠️ Water Pollution Risk\" if prediction == 1 else \"✅ Water is Safe\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"## 💧 Water Safety Prediction App\")\n",
        "    gr.Markdown(\"Enter water parameters below to check if the water is safe.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        salinity = gr.Number(label=\"Salinity (mg/L)\", value=1.0)\n",
        "        do = gr.Number(label=\"Dissolved Oxygen (mg/L)\", value=8.0)\n",
        "        ph = gr.Number(label=\"pH\", value=7.0)\n",
        "        depth = gr.Number(label=\"Water Depth (m)\", value=0.5)\n",
        "        temp = gr.Number(label=\"Temperature (°C)\", value=25.0)\n",
        "\n",
        "    submit = gr.Button(\"Predict\")\n",
        "    result = gr.Textbox(label=\"Prediction Result\")\n",
        "\n",
        "    submit.click(\n",
        "        predict_water_risk,\n",
        "        inputs=[salinity, do, ph, depth, temp],\n",
        "        outputs=result\n",
        "    )\n",
        "\n",
        "app.launch()\n"
      ],
      "metadata": {
        "id": "3KudfaFCO_v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Load your trained model\n",
        "model = joblib.load(\"water_risk_model.pkl\")  # Make sure this file is in the same folder\n",
        "\n",
        "# Prediction function\n",
        "def predict_water_risk(username, salinity, do, ph, depth, temp):\n",
        "    try:\n",
        "        features = np.array([[salinity, do, ph, depth, temp]])\n",
        "        prediction = model.predict(features)[0]\n",
        "        result = \"⚠️ Water Pollution Risk\" if prediction == 1 else \"✅ Water is Safe\"\n",
        "\n",
        "        # Save history\n",
        "        history_path = f\"{username}_history.csv\"\n",
        "        new_entry = pd.DataFrame([{\n",
        "            \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"Salinity\": salinity,\n",
        "            \"DO\": do,\n",
        "            \"pH\": ph,\n",
        "            \"Depth\": depth,\n",
        "            \"Temp\": temp,\n",
        "            \"Prediction\": result\n",
        "        }])\n",
        "\n",
        "        if os.path.exists(history_path):\n",
        "            old_data = pd.read_csv(history_path)\n",
        "            updated_data = pd.concat([old_data, new_entry], ignore_index=True)\n",
        "        else:\n",
        "            updated_data = new_entry\n",
        "\n",
        "        updated_data.to_csv(history_path, index=False)\n",
        "\n",
        "        return result, updated_data\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {str(e)}\", pd.DataFrame()\n",
        "\n",
        "# Define interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🌊 Water Safety Predictor App\")\n",
        "    gr.Markdown(\"Enter your details to check water safety and track your prediction history.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        username = gr.Textbox(label=\"Username\", placeholder=\"Enter your name or ID\")\n",
        "\n",
        "    with gr.Row():\n",
        "        salinity = gr.Number(label=\"Salinity\")\n",
        "        do = gr.Number(label=\"Dissolved Oxygen\")\n",
        "        ph = gr.Number(label=\"pH\")\n",
        "        depth = gr.Number(label=\"Water Depth\")\n",
        "        temp = gr.Number(label=\"Water Temperature\")\n",
        "\n",
        "    predict_btn = gr.Button(\"Predict\")\n",
        "    output_label = gr.Textbox(label=\"Prediction\")\n",
        "    history_table = gr.Dataframe(label=\"Your Prediction History\")\n",
        "\n",
        "    predict_btn.click(\n",
        "        fn=predict_water_risk,\n",
        "        inputs=[username, salinity, do, ph, depth, temp],\n",
        "        outputs=[output_label, history_table]\n",
        "    )\n",
        "\n",
        "# Launch the app (use share=True to get a public link)\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "3zAJcq9fQxuq",
        "outputId": "b34d26c2-9e48-4104-a449-e0f8e1959aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6900435e9d16f2c978.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6900435e9d16f2c978.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}